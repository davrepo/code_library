{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"e1df34c6157544d6a98559d24744f7dd","deepnote_cell_type":"text-cell-p","formattedRanges":[{"fromCodePoint":0,"marks":{"bold":true},"toCodePoint":9,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["‚úÖ Status:  done"]},{"cell_type":"markdown","metadata":{"cell_id":"fe361dc4d96540599b098348c16f733a","deepnote_cell_type":"markdown","tags":[]},"source":["## üìì Exercise 17"]},{"cell_type":"markdown","metadata":{"cell_id":"411fd79edb9c452c9da62e5574eb6ed4","deepnote_cell_type":"markdown","tags":[]},"source":["---"]},{"cell_type":"markdown","metadata":{"cell_id":"b818876ed24745678ea6c478dc8830fa","deepnote_cell_type":"markdown","tags":[]},"source":["Welcome to the exercise 17 in which we will talk about `gradient descent`. Again, first from a theoretical perspective and then we will implement `linear regression` from scratch and find its most optimal parameters using gradient descent."]},{"cell_type":"markdown","metadata":{"cell_id":"2658abd6ef6e4af7876ec60b22c54c31","deepnote_cell_type":"markdown","tags":[]},"source":["### üè∑ GD: theory"]},{"cell_type":"markdown","metadata":{"cell_id":"36748b3d4e06430981a11e217fd1e69a","deepnote_cell_type":"markdown","tags":[]},"source":["---"]},{"cell_type":"markdown","metadata":{"cell_id":"820874b71ee540a9ad066132f36d9107","deepnote_cell_type":"text-cell-callout","formattedRanges":[{"fromCodePoint":0,"marks":{"bold":true},"toCodePoint":23,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["> Fundamental information"]},{"cell_type":"markdown","metadata":{"cell_id":"5ead21f19e024a35b7f668bbd408a4fa","deepnote_cell_type":"markdown","tags":[]},"source":["Let's start with a definition:\n","> `Gradient descent` is simply a way how one can find optimal parameters for given model\n","\n","Now, how is this way defined? Essentially, by the following formula:\n","\n","$\n","\\theta_{new} = \\theta_{old} - \\alpha \\nabla L_m\n","$\n","\n","The big picture of this formula is that we compute the gradient vector of the loss function, (Recall that gradient vector of a function points in a direction of the steepest growth of the given function), we revert its direction using the minus sign to point in the steepest downward direction and scale it by some learning rate parameter $\\alpha$ and finally use the resulting vector to update our model's parameters. If we break down the formula:\n","- $\\theta_{new}$ and $\\theta_{old}$ are the model's parameters after and before making the step in the downwards direction (downwards direction in a sense of the loss since we want to minimize it)\n","- $\\alpha$ is a learning rate that determines how big of a step you do. This is a hyper-parameter so you need to figure this out by some trial and error or grid search. If the steps are too big, then you likely jump over the (local) minimum, whereas if the steps are too small, then you might not even get to the most optimal set of parameters since you get stuck in some local minima. \n","\n","- $\\nabla L_m$ is a gradient vector of a `loss function` of the given model. Below, we will discuss more on how to compute it for different models.\n","\n","Gradient descent is an `iterative algorithm` which means you use the above formula several times to update the parameters, in the below section we will dicuss this more."]},{"cell_type":"markdown","metadata":{"cell_id":"d8ba8d2e0edf4daa808f269270dc7914","deepnote_cell_type":"text-cell-callout","formattedRanges":[{"fromCodePoint":0,"marks":{"bold":true},"toCodePoint":48,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["> Computing the gradient vector of a loss function"]},{"cell_type":"markdown","metadata":{"cell_id":"bd5d39c4d108477d9f0e1d9512b9693e","deepnote_cell_type":"markdown","tags":[]},"source":["We have encountered several parametric models so far. Each of these model has certain `loss` function which depends on the model itself as well as whether we are doing regression or classification since for both tasks we use different loss functions. (usually `MSE` for regression and `Cross-entropy` for classification). Let's make a little summary:\n","- `Linear regression`: here exists a closed formula to find the gradient vector of the `MSE` of LR:\n","\n","$\n","\\nabla L_{LinR} = \\frac{2}{n}X^T(X\\theta - y)\n","$\n","\n","where $X$ is the design matrix (a.k.a. the matrix with training data). Note that this is a vectorized formula for arbitrary number of features. Below, I will show how you can derive this formula for just a single feature.\n","\n","- `Logistic/Softmax regression`: again we have a closed formula to find the gradient vector of `Cross-entropy` loss function:\n","\n","$\n","\\nabla L_{LogR}= X^T(h_{\\theta}(X) - y)\n","$\n","\n","where $h_{\\theta}$ is the logistic/softmax model that takes as an input given sample $x$ and outputs a $1 \\times k$ vector with probabilities for each of the $k$ classes. Therefore, if you feed this function with the whole matrix $X$ with all samples, you will get back $n \\times k$ matrix. $y$ is then $n \\times k$ matrix where in each row, it has $1$ at a position of a true class and for the rest $0$. In other words, $y$ is one-hot encoded. \n","\n","- `Feed forward neural network`: here there is no closed formula, therefore we will use technique called `backpropagation` to obtain the gradient vector, but more on this in the next exercise session. If you want to learn about it now, I suggest you check section 4.2 of this [note](https://github.com/ludekcizinsky/glass-forensic-analysis/blob/main/ml_report.pdf).\n","\n","Just so for the sake of completness on how the closed formulas for the algorithms are derived, we can consider a simple example using `linear regression` with a single feature. Its loss function looks as follows:\n","\n","$\n","J(\\theta_0,\\theta_1) =  \\frac{1}{n} \\sum_{i=1}^n(  h_{\\theta}(x_i) - y_i )^2\n","$\n","\n","Then to obtain the gradient vector, we need to find partial derivative with respect to both parameters:\n","\n","$\n","\\frac{\\partial J}{\\partial \\theta_0}(\\theta_0, \\theta_1) = \\frac{2}{n}\\sum_{i = 1}^{n}(x_i \\theta_1 + \\theta_0 - y_i )\n","$\n","\n","$\n","\\frac{\\partial J}{\\partial \\theta_1}(\\theta_0, \\theta_1) = \\frac{2}{n}\\sum_{i = 1}^{n}x_i(x_i \\theta_1 + \\theta_0 - y_i )\n","$\n","\n","Then if you vectorize it, you obtain the closed formula as mentioned above."]},{"cell_type":"markdown","metadata":{"cell_id":"514d7241bdb64433957c44043c579433","deepnote_cell_type":"text-cell-callout","formattedRanges":[{"fromCodePoint":0,"marks":{"bold":true},"toCodePoint":28,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["> Training algorithms using GD"]},{"cell_type":"markdown","metadata":{"cell_id":"6faec454e029423689b56d93902386a6","deepnote_cell_type":"markdown","tags":[]},"source":["Let's first define some terminology:\n","**Epoch.** One epoch corresponds to training a model on the whole training dataset. Usually used within the context of Neural Networks as there you might feed forward the whole dataset through network several times. But it of course can be used for linear or logistic regression.\n","\n","**Batch.** Batch refers to a set of training data. Batch‚Äôs size can be from 1 to N where N is the number of training data points.\n","\n","Now, how do you actually choose proper batch size: There are fundamentally two scenarios:\n","\n","- Small (if 1 then it is called `Stochastic`): you are able to compute gradient faster, but you pay a cost in terms of being consistent in terms your steps through the cost function‚Äôs space. In other words, the cost during training varies a lot. (training history line goes up and down a lot)\n","- `Mini-batch`: it lies between the large and small batch size, I would say in general, it might be around 5 % of the training data.\n","- Large: The cost should slowly but nicely decrease (training history line is smooth as there are no spikes)\n","\n","In addition, in practice, you might want **GD to stop early** in the case where there is not much of an improvement in terms of **decrease in the loss**.\n","\n","Finally, let's talk about **pros and cons**  of the `GD` as an optimizer:\n","\n","Pros\n","\n","- Intuitive to understand\n","- Used by many ML libraries as a default\n","- Works well for cost functions which have **convex space** (i.e. no local minimums)\n","\n","Cons\n","\n","- Assumes that cost function is differentiable and continuous\n","- It can get easily stuck in a local minimum"]},{"cell_type":"markdown","metadata":{"cell_id":"2407768519bd4b489d32ddf4997db523","color":"yellow","deepnote_cell_type":"text-cell-callout","formattedRanges":[{"fromCodePoint":0,"marks":{"bold":true},"toCodePoint":15,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["> Section summary"]},{"cell_type":"markdown","metadata":{"cell_id":"31656350a34340c2a0d6b9b00d7f0c63","deepnote_cell_type":"markdown","tags":[]},"source":["After this section, you should be able to explain:\n","- how `GD` works in detail\n","- how we can use it to train various algorithms such as `Linear` or `Logistic` regression\n","- how to setup hyper-parameters  such as learning rate or batch size\n","- pros and cons of `GD`"]},{"cell_type":"markdown","metadata":{"cell_id":"d9f194ba77f347a6aa971094b8609e31","deepnote_cell_type":"markdown","tags":[]},"source":["### üè∑ GD: practice"]},{"cell_type":"markdown","metadata":{"cell_id":"351941bc8c7042c0b1b202924ce761df","deepnote_cell_type":"markdown","tags":[]},"source":["---"]},{"cell_type":"markdown","metadata":{"cell_id":"06152d659a394412b086a6f382451aa2","deepnote_cell_type":"markdown","tags":[]},"source":["In this section, we focus on using gradient descent in practice. More specifially, we use it to optimize `Linear regression` model. Therefore:\n","- see [`implementation`](https://github.com/ludekcizinsky/nano-learn/blob/main/nnlearn/linear/_linr.py) for an example how you could do it, especially note the function `_train` where most of the core functionality is done\n","- see [`wine dataset example`](https://github.com/ludekcizinsky/nano-learn/tree/main/examples/linr-wine) to inspect how different hyper-parameters influence the overall result. (I suggest you clone the repository and play around with the hyper-parameters if you want)"]},{"cell_type":"markdown","metadata":{"cell_id":"7d9d45779c3c449fba90901b9128297f","color":"yellow","deepnote_cell_type":"text-cell-callout","formattedRanges":[{"fromCodePoint":0,"marks":{"bold":true},"toCodePoint":15,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["> Section summary"]},{"cell_type":"markdown","metadata":{"cell_id":"27b701822c3246c491139477211944e0","deepnote_cell_type":"markdown","tags":[]},"source":["This section should give you a practical intuition on how `GD` works. It should give a more concrete picture how the whole process works including choosing different number of epochs and batch sizes."]},{"cell_type":"markdown","metadata":{"cell_id":"329481416f214ef88d872faab4e2cb3f","deepnote_cell_type":"markdown","tags":[]},"source":["---"]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=6e0f1839-a5f7-4da8-b3bc-f4b80036136e' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"1757f09ce7254335a01f15282afd9d3c","language_info":{"name":"python"},"orig_nbformat":2},"nbformat":4,"nbformat_minor":0}
