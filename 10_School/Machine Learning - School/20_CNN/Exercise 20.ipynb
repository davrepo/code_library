{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"91d4cded98d94cc29a08a11e23084e28","deepnote_cell_type":"text-cell-p","formattedRanges":[{"fromCodePoint":0,"marks":{"bold":true},"toCodePoint":7,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["Status:  ‚úÖ done "]},{"cell_type":"markdown","metadata":{"cell_id":"b7a06b24b18c4c20bee14d084580b3f1","deepnote_cell_type":"markdown","tags":[]},"source":["## Exercise 20"]},{"cell_type":"markdown","metadata":{"cell_id":"8702c6db41744661a2e89aed9c74c138","deepnote_cell_type":"markdown","tags":[]},"source":["---"]},{"cell_type":"markdown","metadata":{"cell_id":"3842a6b189e043f79e68413f662f0c70","deepnote_cell_type":"markdown","tags":[]},"source":["Welcome to the 20th exercise in which we will practice `CNN`s. First, we will go over a couple of theoretical examples and then we move to actually training one `CNN` for the MNIST dataset."]},{"cell_type":"markdown","metadata":{"cell_id":"69bc1de7f5b64f6397b2b8e5649554de","deepnote_cell_type":"text-cell-callout","formattedRanges":[{"fromCodePoint":0,"marks":{"bold":true},"toCodePoint":7,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["> Imports"]},{"cell_type":"code","execution_count":4,"metadata":{"cell_id":"ebdfea3cfe5b42b7ab3691d3618cf6c2","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":4681,"execution_start":1668164091794,"source_hash":"133f318","tags":[]},"outputs":[],"source":["from numpy.core.fromnumeric import shape\n","import torch\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","from torch.utils.data import DataLoader\n","from torch import nn\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, accuracy_score"]},{"cell_type":"markdown","metadata":{"cell_id":"a07e2530550e4c86a252fd54b5ce89ac","deepnote_cell_type":"markdown","tags":[]},"source":["### üè∑ CNN Theory"]},{"cell_type":"markdown","metadata":{"cell_id":"5187082a17434f39a10ef511bb8f9c36","deepnote_cell_type":"markdown","tags":[]},"source":["---"]},{"cell_type":"markdown","metadata":{"cell_id":"2caf060ffcf048f691426da0ecdf1136","deepnote_cell_type":"text-cell-callout","formattedRanges":[{"fromCodePoint":0,"marks":{"bold":true},"toCodePoint":11,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["> Quick recap"]},{"cell_type":"markdown","metadata":{"cell_id":"351ba0da66bd4d08a0176fbface59432","deepnote_cell_type":"markdown","tags":[]},"source":["If you need 5 min read recap of the most important concepts from `CNN`, I suggest you read my [note](https://www.notion.so/ludekcizinsky/NN-and-CNN-8c739d9486c142f28df7acb6d99ccccc#cf0004b507bd4f8da9ee5b1bcb1976fc)."]},{"cell_type":"markdown","metadata":{"cell_id":"291c5ecfdc67414d9f1ac011783ba38a","deepnote_cell_type":"text-cell-callout","formattedRanges":[{"fromCodePoint":0,"marks":{"bold":true},"toCodePoint":68,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["> Convolutional layer (filters, padding, parameters), relation to FFNN"]},{"cell_type":"markdown","metadata":{"cell_id":"6673d2537db140d4b217de1c0317a366","deepnote_cell_type":"markdown","tags":[]},"source":["Let's consider a simple example where:\n","- as an input we take $32 \\times 32$ grayscale image (i.e. we can represent it with a simple matrix)\n","- we run the image through three $5 \\times 5$ filters\n","- we will use `no padding` around the image\n","\n","Now, what would be the size of the outputted channels after we run the given filters on the grayscale image? That is fairly easy to compute:\n","- input dimension is $N = 32$\n","- filter dimension is $F = 5$\n","- we use no padding, therefore the input dimension $N$ will shrink by $F - 1$\n","- therefore, the output dimension $O$ will be:\n","\n","$\n","O = N - (F - 1)\n","$\n","\n","- more specifically in our case:\n","\n","$\n","O = 32 - (5 - 1) = 28\n","$\n","\n","Now, what if we want to end up with an output of the same dimension as an input? Then we just need to shift an angle on what we are interested in, which is what should be the input dimension $N$:\n","\n","$$\n","\\begin{aligned}\n","O = N - (F - 1) \\\\\n","- N = -O - (F - 1) \\\\\n","N = O + (F - 1)\n","\\end{aligned}\n","$$\n","\n","So given the desired output size $O$ and filter size $F$, we can compute the needed input size $N$. In our particular case:\n","\n","$\n","N = 32 + (5 - 1) = 36\n","$\n","\n","Therefore, we need to add 4 pixels to each row and column in the input, i.e., on each side of the input image, we need to add 2 pixels. Using this `padded` image, we can obtain output image with the same dimension. **Note: I have assumed stride length to be 1.**\n","\n","Now, how many parameters do we actually have in this convolutional layer? Well, each filter has $25$ parameters (recall we use $5 \\times 5$ filters) and since we have three filters, then this means we have 75 parameters in total.\n","\n","Last but not the least, why do we actually need convolutional layer? Well, the input image has 1024 pixels, if we would just feed these to our `FFNN`, we would lose a lot of information, especially about the order of the pixels. Therefore, the core idea behind `convolutional layer` is to have model learn some patterns from the image and THEN feed these patterns as an input to our `FFNN`."]},{"cell_type":"markdown","metadata":{"cell_id":"89bd960b50384da7a2305d6b06d29ddc","deepnote_cell_type":"text-cell-callout","formattedRanges":[{"fromCodePoint":0,"marks":{"bold":true},"toCodePoint":67,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["> CNN and memory consumption (point: we actually need pooling layers)"]},{"cell_type":"markdown","metadata":{"cell_id":"8e805df235a7460984931b08cb9accb9","deepnote_cell_type":"markdown","tags":[]},"source":["Now, we will take a little thought tour into the space of CNN's hardware utilization, more specifically RAM. Let's assume the following for our `CNN`:\n","- for any convolutional layer described below, we always use $3 \\times 3$ filters\n","- when convolving, we use stride being equal to 2 and the same 'padding' strategy, i.e., output dimension is equal to the output dimension\n","- we have three convolutional layers where\n","    - first outputs 100 channels\n","    - second outputs 200 channels\n","    - and third outputs 400 channels\n","- as an input we take RGB images of resolution $200 \\times 300$ pixels\n","\n","First, we want to answer the following question:\n","\n","> How much RAM will be required when computing a single sample pass through this `CNN` assuming we use 32-bit floats to represent any parameter/value?\n","\n","This question can be broken down into two parts:\n","- how much RAM do we need to store the model's parameters?\n","- how much RAM do we need to store the input $x$ and then the outputted channels?\n","\n","Let's start with the first subquestion by computing the number of parameters for each convolutional layer:\n","- **Convolutional layer 1:** Here we take the RGB input and transform it into 100 new channels. To obtain each of these channels, we will need 3 filters (for each channel), therefore, per output channel we will have $3 \\times 3 \\times 3 = 27$ parameters. So in total, we need to train **2'700 parameters** for the first convolutional layer.\n","\n","- **Convolutional layer 2:** Here we take as an input $100$ channels, therefore for each output channel, we need $100 \\times 3 \\times 3 = 900$ parameters. Since we have $200$ output channels, in total we need to train **180'000** parameters.\n","\n","- **Convolutional layer 3:** Here we take as an input $200$ channels, therefore for each output channel, we will need $200 \\times 3 \\times 3 = 1800$ parameters. So, in total, we will need to train **720'000 parameters**.\n","\n","Therefore, summing over all parameters, our network has **902¬†700 trainable parameters**. Assuming each of these will be represented as an $32$-bit float which is 4 bytes, then all these parameters take $3'610'800$ bytes which is roughly $3'610'800/1000/1000 \\approx 3.45$ MB. \n","\n","Now, we need to answer the second subquestion, which is how much memory do the actual channels take? Again, let's go layer by layer:\n","\n","- **Convolutional layer 1:** we take as an input 3D array which has in total $3 \\times 200 \\times 300$ values. As an output, we obtain 100 channels, but of what what dimension? Well, on each of the image channels, we apply $3 \\times 3$ filter with stride 2 (i.e. we skip every other pixel in each direction - row and column wise). This means that for each channel (RGB) we compute $100 \\times 150$ output and then we summarize these outputs into a single output of the same size, so per output channel we will therefore need $4 \\times 100 \\times 150$ values, which means going through the first convolutional layer will require:\n","\n","$\n","(3 + 1) \\times 100 \\times 150 \\times 100 = 6'000'000 \\text{ values}\n","$\n","\n","- **Convolutional layer 2:** similarly for this layer:\n","\n","$\n","(100 + 1) \\times 50 \\times 75 \\times 200 = 75'750'000 \\text{ values}\n","$\n","\n","- **Convolutional layer 3:** and finally for the last layer:\n","\n","$\n","(200 + 1) \\times 25 \\times 37 \\times 400 = 74'370'000 \\text{ values}\n","$\n","\n","So in total, if we wanted to fit all values into main memory, we would need:\n","\n","$\n","((6'000'000 + 75'750'000 + 74'370'000)\\times 4)/1000/1000 \\approx 624.5 \\text{ MB}\n","$\n","\n","Therefore, to answer our initial question completely, we would roughly need **628 MB of memory**. \n","\n","Recall that we have so far assummed that we simply use a single sample/image as an input, now another question might be:\n","\n","> how much memory will we actually need if we use 50 images as an input?\n","\n","This is fairly straightforward:\n","\n","$\n","624.5 \\times 50 + 3.5 \\approx 31 \\text{ GB}\n","$\n","\n","With all of this being said, it feels like our CNN is missing something since we want to reduce the memory consumption if possible because otherwise it would be fairly difficult to train CNNs with such architectures. This is where pooling layers come into the picture. Pooling layers help us reduce the dimensions of the output layers by essentially summarizing them and as such reducing the dimension by several factors."]},{"cell_type":"markdown","metadata":{"cell_id":"05cf9dad6e31471e8182403efcdb255f","color":"yellow","deepnote_cell_type":"text-cell-callout","formattedRanges":[{"fromCodePoint":0,"marks":{"bold":true},"toCodePoint":15,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["> Section summary"]},{"cell_type":"markdown","metadata":{"cell_id":"b82827797d7b4fd5be7e495a2219ffad","deepnote_cell_type":"markdown","tags":[]},"source":["In this section, we went over the core CNN concepts:\n","\n","- how to use **filters**\n","- how to use **padding** if we want/or not to keep the dimension of the output same as of the input\n","- compute the **number of parameters** for given CNN architecture\n","- role of **stride length** in terms of output dimension\n","- role of **pooling layer**\n","\n","You should be able to explain all of these after going through this section. As a bonus, it would be nice if you could also make a simple example showing memory consumption of the given CNN architecture."]},{"cell_type":"markdown","metadata":{"cell_id":"4e80d21ddc914fdbb29717ce1e3f596f","deepnote_cell_type":"markdown","tags":[]},"source":["### üè∑ Practical example"]},{"cell_type":"markdown","metadata":{"cell_id":"081bf3c1c14c47e4bc3e663dbbfe1b81","deepnote_cell_type":"markdown","tags":[]},"source":["---"]},{"cell_type":"markdown","metadata":{"cell_id":"201b7141ea6a4861950df1c3bd12734e","deepnote_cell_type":"text-cell-callout","formattedRanges":[{"fromCodePoint":0,"marks":{"bold":true},"toCodePoint":20,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["> Intro to the problem"]},{"cell_type":"markdown","metadata":{"cell_id":"4cafb18653074e4ca9de42d6c0fdc9e3","deepnote_cell_type":"markdown","tags":[]},"source":["The purpose of this exercise is to train a model which can predict one of the 10 clothes' labels as defined in the [Fashion-Mnist dataset](https://github.com/zalandoresearch/fashion-mnist). More specifically, we divide this section into two major parts:\n","\n","- construct a model using `PyTorch` - we will implement [LeNet architecture](LeNet.pdf)\n","- construct a pipeline that will train the model and then show its performance on test data"]},{"cell_type":"markdown","metadata":{"cell_id":"e9bced60ae26444d9b6d13aa25934a0b","deepnote_cell_type":"text-cell-callout","formattedRanges":[{"fromCodePoint":0,"marks":{"bold":true},"toCodePoint":22,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["> Constructing the model"]},{"cell_type":"markdown","metadata":{"cell_id":"cfeb19694bc14d3d91c0148c3586376a","deepnote_cell_type":"markdown","tags":[]},"source":["The LeNet architecture is implemented in the `__init__` method. The rest of the functions will help us to define the pipeline down below."]},{"cell_type":"code","execution_count":5,"metadata":{"cell_id":"0f92a2c0a5b3438f8fceae1c388eee58","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":0,"execution_start":1668164820863,"source_hash":"ace27179","tags":[]},"outputs":[],"source":["class NeuralNetwork(nn.Module):\n","    def __init__(self, **INPUT):\n","\n","        # Inherit from nn.Module\n","        super(NeuralNetwork, self).__init__()\n","\n","        # Define activation function\n","        self.af = INPUT.get('af')\n","\n","        # Define drop ratio\n","        self.dpr = INPUT.get('dpr')\n","\n","        # Define neural network architecture\n","        self.nn = nn.Sequential(\n","            # C1: 6@28x28\n","            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2),\n","            nn.BatchNorm2d(6),\n","            self.af(),\n","            nn.AvgPool2d(kernel_size=2, stride=2),\n","\n","            # C2: 16@10x10\n","            nn.Dropout(self.dpr),\n","            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n","            nn.BatchNorm2d(16),\n","            self.af(),\n","            nn.AvgPool2d(kernel_size=2, stride=2),\n","\n","            # Apply flattening on the output\n","            nn.Flatten(),\n","\n","            # Dense part\n","            # * L1\n","            nn.Dropout(self.dpr),\n","            nn.Linear(400, 120),\n","            nn.BatchNorm1d(120),\n","            self.af(),\n","\n","            # * L2\n","            nn.Dropout(self.dpr),\n","            nn.Linear(120, 84),\n","            nn.BatchNorm1d(84),\n","            self.af(),\n","\n","            # * L3\n","            nn.Dropout(self.dpr),\n","            nn.Linear(84, 10)\n","\n","        )\n","\n","        # Define batch size\n","        self.batch_size = INPUT.get('batch_size')\n","\n","        # Define datasets\n","        self.training = DataLoader(\n","            INPUT.get('trd'), batch_size=self.batch_size, shuffle=True)\n","        self.validation = DataLoader(\n","            INPUT.get('vd'), batch_size=self.batch_size, shuffle=True)\n","        self.test_data = DataLoader(\n","            INPUT.get('ted'), batch_size=len(INPUT.get('ted')), shuffle=True)\n","\n","        # Define loss funtion\n","        self.loss_fn = INPUT.get('loss_fn')\n","\n","        # Define learning rate\n","        self.lr = INPUT.get('lr')\n","\n","        # Define number of epochs\n","        self.epochs = INPUT.get('epochs')\n","\n","        # Define optimizer\n","        self.optimizer = INPUT.get('optim')(self.parameters(), lr=self.lr)\n","\n","        # Save training progress\n","        self.loss_history = []\n","        self.acc_history = []\n","\n","    def forward(self, x):\n","        logits = self.nn(x)\n","        return logits\n","\n","    def train_loop(self):\n","\n","        size = len(self.training.dataset)\n","        for batch, (X, y) in enumerate(self.training):\n","\n","            # Compute prediction and loss\n","            pred = self.forward(X)\n","            loss = self.loss_fn(pred, y)\n","\n","            # Backpropagation\n","            self.optimizer.zero_grad()\n","            loss.backward()\n","            self.optimizer.step()\n","\n","            if batch % 100 == 0:\n","                loss, current = loss.item(), batch * len(X)\n","                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n","\n","    def val_loop(self):\n","        size = len(self.validation.dataset)\n","        num_batches = len(self.validation)\n","        test_loss, correct = 0, 0\n","\n","        with torch.no_grad():\n","            for X, y in self.validation:\n","                pred = self.forward(X)\n","                test_loss += self.loss_fn(pred, y).item()\n","                correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","\n","        test_loss /= num_batches\n","        correct /= size\n","        print(\n","            f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n","\n","        # Save it to history\n","        self.acc_history.append(correct)\n","        self.loss_history.append(test_loss)\n","\n","    def visualize(self):\n","        x = [i for i in range(self.epochs)]\n","        y1 = self.acc_history\n","        y2 = self.loss_history\n","        plt.plot(x, y1)\n","        plt.plot(x, y2)\n","        plt.show()\n","\n","    def fit(self):\n","\n","        for t in range(self.epochs):\n","            print(f\"Epoch {t+1}\\n-------------------------------\")\n","            self.train_loop()\n","            self.val_loop()\n","        print(\"Done!\")\n","\n","    def predict(self, x):\n","        logits = self.forward(x)\n","        softmax = nn.Softmax(dim=1)\n","        return softmax(logits).argmax(1)\n","\n","    def test(self):\n","\n","        # Get data\n","        X, y = next(iter(self.test_data))\n","\n","        # Predict values\n","        y_hat = self.predict(X)\n","\n","        print(\"Accuracy score for test data\")\n","        print(\"-\"*60)\n","        print(f\"Acc: {accuracy_score(y, y_hat)*100} %\")\n","        print()\n","        print(\"Confusion matrix for test data\")\n","        print(\"-\"*60)\n","        print(confusion_matrix(y, y_hat))"]},{"cell_type":"markdown","metadata":{"cell_id":"394ecd383101485cbb14a492aa71c681","deepnote_cell_type":"text-cell-callout","formattedRanges":[{"fromCodePoint":0,"marks":{"bold":true},"toCodePoint":8,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["> Pipeline"]},{"cell_type":"markdown","metadata":{"cell_id":"03bb8f85effe47afad8a58f61189da5b","deepnote_cell_type":"markdown","tags":[]},"source":["Here, we simply get our training and test data. Then train the model and finally show its performance."]},{"cell_type":"code","execution_count":6,"metadata":{"cell_id":"d2560eb816a747e2ba49c772c0ae8603","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":178941,"execution_start":1668164201303,"source_hash":"4d1c255d","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["------------------------------------------------------------\n","[0] Loading data\n","------------------------------------------------------------\n","------------------------------------------------------------\n","[1] Loading dataset done\n","------------------------------------------------------------\n","------------------------------------------------------------\n","[2] Initialize model\n","------------------------------------------------------------\n","------------------------------------------------------------\n","[3] Model initialized and ready to be trained\n","------------------------------------------------------------\n","------------------------------------------------------------\n","[4] Started to train model\n","------------------------------------------------------------\n","Epoch 1\n","-------------------------------\n","loss: 2.398207  [    0/50000]\n","loss: 0.575191  [10000/50000]\n","loss: 0.569845  [20000/50000]\n","loss: 0.622981  [30000/50000]\n","loss: 0.350341  [40000/50000]\n","Test Error: \n"," Accuracy: 83.8%, Avg loss: 0.446889 \n","\n","Epoch 2\n","-------------------------------\n","loss: 0.349204  [    0/50000]\n","loss: 0.526129  [10000/50000]\n","loss: 0.414245  [20000/50000]\n","loss: 0.424397  [30000/50000]\n","loss: 0.291979  [40000/50000]\n","Test Error: \n"," Accuracy: 86.8%, Avg loss: 0.359216 \n","\n","Epoch 3\n","-------------------------------\n","loss: 0.367372  [    0/50000]\n","loss: 0.351450  [10000/50000]\n","loss: 0.385417  [20000/50000]\n","loss: 0.280081  [30000/50000]\n","loss: 0.328399  [40000/50000]\n","Test Error: \n"," Accuracy: 87.7%, Avg loss: 0.332462 \n","\n","Epoch 4\n","-------------------------------\n","loss: 0.247830  [    0/50000]\n","loss: 0.299894  [10000/50000]\n","loss: 0.355225  [20000/50000]\n","loss: 0.254547  [30000/50000]\n","loss: 0.315243  [40000/50000]\n","Test Error: \n"," Accuracy: 87.6%, Avg loss: 0.336419 \n","\n","Epoch 5\n","-------------------------------\n","loss: 0.345803  [    0/50000]\n","loss: 0.268602  [10000/50000]\n","loss: 0.368632  [20000/50000]\n","loss: 0.343816  [30000/50000]\n","loss: 0.330350  [40000/50000]\n","Test Error: \n"," Accuracy: 88.5%, Avg loss: 0.313823 \n","\n","Done!\n","------------------------------------------------------------\n","[5] Model trained successfully\n","------------------------------------------------------------\n","------------------------------------------------------------\n","[6] Predicting values for test data\n","------------------------------------------------------------\n","Accuracy score for test data\n","------------------------------------------------------------\n","Acc: 88.03999999999999 %\n","\n","Confusion matrix for test data\n","------------------------------------------------------------\n","[[787   1  31  26   4   3 144   0   4   0]\n"," [  0 973   2  16   5   0   3   0   1   0]\n"," [ 10   1 912  10  35   0  32   0   0   0]\n"," [  6   4  16 892  44   0  34   0   4   0]\n"," [  0   0 192  25 731   0  50   0   2   0]\n"," [  0   0   0   0   0 975   0  16   4   5]\n"," [104   0 123  31  64   0 672   0   6   0]\n"," [  0   0   0   0   0  31   0 953   2  14]\n"," [  3   2   9   5   3   1   4   0 973   0]\n"," [  1   0   0   0   0   8   0  54   1 936]]\n","------------------------------------------------------------\n","[7] End of the pipeline.\n","------------------------------------------------------------\n"]}],"source":["print(\"-\"*60)\n","print(\"[0] Loading data\")\n","print(\"-\"*60)\n","\n","# Get training\n","training_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor()\n",")\n","\n","# Split training into training and validation\n","g_cpu = torch.Generator()\n","g_cpu.manual_seed(3)\n","training_data, val_data = torch.utils.data.random_split(\n","    training_data, [50000, 10000])\n","\n","# Get test data\n","test_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False,\n","    download=False,\n","    transform=ToTensor()\n",")\n","print(\"-\"*60)\n","print(\"[1] Loading dataset done\")\n","print(\"-\"*60)\n","\n","print(\"-\"*60)\n","print(\"[2] Initialize model\")\n","print(\"-\"*60)\n","INPUT = {\n","    'batch_size': 100,\n","    'trd': training_data,\n","    'vd': val_data,\n","    'ted': test_data,\n","    'loss_fn': nn.CrossEntropyLoss(),\n","    'lr': 1e-1,\n","    'epochs': 5,\n","    'af': nn.Sigmoid,\n","    'optim': torch.optim.Adam,\n","    'dpr': 1e-3\n","\n","}\n","model = NeuralNetwork(**INPUT)\n","\n","print(\"-\"*60)\n","print(\"[3] Model initialized and ready to be trained\")\n","print(\"-\"*60)\n","\n","print(\"-\"*60)\n","print(\"[4] Started to train model\")\n","print(\"-\"*60)\n","model.fit()\n","print(\"-\"*60)\n","print(\"[5] Model trained successfully\")\n","print(\"-\"*60)\n","\n","print(\"-\"*60)\n","print(\"[6] Predicting values for test data\")\n","print(\"-\"*60)\n","model.test()\n","\n","print(\"-\"*60)\n","print(\"[7] End of the pipeline.\")\n","print(\"-\"*60)"]},{"cell_type":"markdown","metadata":{"cell_id":"58e3c39f3db1426c8b2e9c280be421fe","color":"yellow","deepnote_cell_type":"text-cell-callout","formattedRanges":[{"fromCodePoint":0,"marks":{"bold":true},"toCodePoint":15,"type":"marks"}],"is_collapsed":false,"tags":[]},"source":["> Section summary"]},{"cell_type":"markdown","metadata":{"cell_id":"479acbabfccf4f5db4e43ceafc3f2f29","deepnote_cell_type":"markdown","tags":[]},"source":["After going through this section, you should be able to solve a more complex machine learning problem using `CNN` built with `PyTorch`. If you have done your work well enough, I believe this is a nice project to show to a potential employer when proving that you can work with `PyTorch`. üôè"]},{"cell_type":"markdown","metadata":{"cell_id":"2176fdd38a1e4d64aa8dbe7d94597284","deepnote_cell_type":"markdown","tags":[]},"source":["---"]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=44b4318f-b707-4245-8a54-52edfdffa4de' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"dd926b1b8ea94ce79538cc9365bc74b7","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"orig_nbformat":2},"nbformat":4,"nbformat_minor":0}
