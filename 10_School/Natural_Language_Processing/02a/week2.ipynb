{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 - NLP and Deep Learning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3: Annotation and POS tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment consists of 2 parts: first you annotate the data, then you compare your annotations against the annotations of another annotator. The annotation from the other annotator will be made available at 15:00 on 05-02-2024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Annotation \n",
    "\n",
    "Find the file with your ITU username in `assignments/week2/pos-data/`. In this file, you will find 20\n",
    "sentences which are pre-tokenized and in conll format. Behind each word you are supposed to annotate the pos tag, with one tab in between. The final file should look like this:\n",
    "\n",
    "```\n",
    "Seriously\tADV\n",
    ":\tPUNCT\n",
    "do\tAUX\n",
    "not\tPART\n",
    "waste\tVERB\n",
    "your\tPRON\n",
    "time\tNOUN\n",
    ".\tPUNCT\n",
    "\n",
    "```\n",
    "\n",
    "You should use a tab between the word and its tag. Please check with the script posCheck.py\n",
    "whether the file format is correct. Usage: `python3 check-pos.py origFile annotatedFile`\n",
    "For annotation guidelines we refer to the slides and https://universaldependencies.org/u/pos/all.html. Alternatively, it might be helpful to look at example annotations, which are provided in:\n",
    "`assignments/week2/pos-data/ewt.train.txt`\n",
    "\n",
    "### Annotation tool\n",
    "If you prefer to work with an annotation tool instead of text files directly, you can use an annotation tool. You have to make sure to upload the data to LearnIt in the format described above though. I would recommend [Eevee](https://axelsorensen.github.io/EeveeTest/) because it is easy to set up and it works natively with this data format. An Eevee configuration file is available in the repo (`assignments/week2/eevee_pos.json`), and an explanation on how to use it is available from the [repo](https://github.com/AxelSorensenDev/Eevee). In short, you would have to import the configuration file with the ``Import task button``, and then import the POS data with the ``Import \"conll-like\" file`` button, then you can click ``Annotate`` and get started. The tool works completely in your browser, so make sure to download a backup of your data at a regular interval. Also, it has been made in collaboration with Rob, and any feedback is more than welcome. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Annotation Quality\n",
    "If you finished before the annotations of the other annotator are released (15:00) you can double check your annotations, already start implementing the following questions (with a dummy file) or ask a TA for the file. \n",
    "\n",
    "* a) Calculate the accuracy between you and the other annotator, how often did you agree?\n",
    "* b) Now implement Cohen’s Kappa score, and calculate the Kappa for your annotation sample. In which range\n",
    "does your Kappa score fall?\n",
    "* c) Take a closer look at the cases where you disagreed with the other annotator; are these disagreements due\n",
    "to ambiguity, or are there mistakes in the annotation? Would you classify your agreement in the same category as it falls in the standard kappa interpretation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jhou.conll is self-annotated data\n",
    "self_data = []\n",
    "with open(\"pos-data/jhou.conll\") as f:\n",
    "    for line in f:\n",
    "        # Split line into tokens and POS tag, and ignore lines that are empty or not annotations\n",
    "        if line.strip():\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) > 1:  # Ensure the line has enough parts to be considered an annotation\n",
    "                self_data.append((parts[0], parts[1]))  # Token and its POS tag\n",
    "\n",
    "# jhou.19.other.conll is ground-truth data\n",
    "gold_data = []\n",
    "with open(\"pos-data/jhou.19.other.conll\") as f:\n",
    "    for line in f:\n",
    "        # Split line into tokens and POS tag, and ignore lines that are empty or not annotations\n",
    "        if line.strip():\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) > 1:  # Ensure the line has enough parts to be considered an annotation\n",
    "                gold_data.append((parts[0], parts[1]))  # Token and its POS tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('you', 'PROPN'),\n",
       "  ('mean', 'VERB'),\n",
       "  ('miramar', 'PROPN'),\n",
       "  ('florida', 'PROPN'),\n",
       "  ('theyy', 'PRON')],\n",
       " [('you', 'PRON'),\n",
       "  ('mean', 'VERB'),\n",
       "  ('miramar', 'PROPN'),\n",
       "  ('florida', 'PROPN'),\n",
       "  ('theyy', 'PRON')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_data[:5], gold_data[:5]  # Display the first 5 annotations from each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.38%\n",
      "Matches: 168\n",
      "Total: 178\n"
     ]
    }
   ],
   "source": [
    "# a) Calculate the accuracy between self and the ground-truth annotator, how often did you agree?\n",
    "\n",
    "# Calculate accuracy\n",
    "matches = sum(1 for self, gold in zip(self_data, gold_data) if self == gold)\n",
    "total = len(gold_data)  # Assuming gold_data is the ground-truth\n",
    "\n",
    "accuracy = matches / total if total > 0 else 0\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "print(f\"Matches: {matches}\")\n",
    "print(f\"Total: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jackh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\jackh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\jackh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9370179038992287"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b) Now implement Cohen’s Kappa score, and calculate the Kappa for your annotation sample. In which range does your Kappa score fall?\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Extract only the POS tags for comparison\n",
    "self_tags = [tag for _, tag in self_data]\n",
    "gold_tags = [tag for _, tag in gold_data]\n",
    "\n",
    "# Calculate Cohen's Kappa score\n",
    "kappa_score = cohen_kappa_score(self_tags, gold_tags)\n",
    "kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('you', 'PROPN', 'PRON'),\n",
       " ('I', 'PROPN', 'PRON'),\n",
       " ('There', 'ADV', 'PRON'),\n",
       " ('are', 'AUX', 'VERB'),\n",
       " ('cos', 'CCONJ', 'SCONJ'),\n",
       " ('to', 'PART', 'ADP'),\n",
       " ('HORSE', 'NOUN', 'PROPN'),\n",
       " ('horse', 'NOUN', 'PROPN'),\n",
       " ('starting', 'VERB', 'NOUN'),\n",
       " ('National', 'PROPN', 'ADJ')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify the cases where there was a disagreement between the self and ground-truth annotations\n",
    "\n",
    "disagreements = [(self_token, self_tag, gold_tag) for (self_token, self_tag), (_, gold_tag) in zip(self_data, gold_data) if self_tag != gold_tag]\n",
    "\n",
    "disagreements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon examining the cases of disagreement between my annotations and the ground-truth data, I find the following discrepancies:\n",
    "\n",
    "1. \"you\" annotated as `PROPN` (proper noun) vs. `PRON` (pronoun)\n",
    "2. \"I\" annotated as `PROPN` vs. `PRON`\n",
    "3. \"There\" annotated as `ADV` (adverb) vs. `PRON`\n",
    "4. \"are\" annotated as `AUX` (auxiliary verb) vs. `VERB`\n",
    "5. \"cos\" annotated as `CCONJ` (coordinating conjunction) vs. `SCONJ` (subordinating conjunction)\n",
    "6. \"to\" annotated as `PART` (particle) vs. `ADP` (adposition)\n",
    "7. \"HORSE\" annotated as `NOUN` vs. `PROPN`\n",
    "8. \"horse\" annotated as `NOUN` vs. `PROPN`\n",
    "9. \"starting\" annotated as `VERB` vs. `NOUN`\n",
    "10. \"National\" annotated as `PROPN` vs. `ADJ` (adjective)\n",
    "\n",
    "These disagreements could be due to several factors:\n",
    "\n",
    "- **Ambiguity in Linguistic Usage:** Words like \"you\", \"I\", and \"There\" can have different interpretations based on context, leading to ambiguity in categorizing them strictly as either proper nouns or pronouns, and adverbs or pronouns, respectively.\n",
    "- **Differences in Interpretation:** The classification of words like \"are\" (as `AUX` or `VERB`), \"cos\" (as `CCONJ` or `SCONJ`), \"to\" (as `PART` or `ADP`), and \"starting\" (as `VERB` or `NOUN`) can depend on the annotator's interpretation of the grammatical structure they are part of.\n",
    "- **Mistakes in Annotation:** It's possible that either the self-annotation or the ground-truth data contains errors.\n",
    "\n",
    "Given the Cohen's Kappa score of approximately 0.937, indicating \"almost perfect agreement,\" it's clear that these disagreements are relatively minor compared to the overall dataset. However, examining these disagreements in detail reveals that both ambiguity and possible mistakes in annotation are present. Depending on the context of these words in sentences, some disagreements could be justified, suggesting that while the Kappa score is high, careful review and consensus on guidelines could potentially resolve these ambiguities and improve annotation consistency further.\n",
    "\n",
    "Would I classify our agreement in the same category as the standard Kappa interpretation? Given the types of disagreements observed, the high Kappa score seems justified as it indicates a high level of agreement despite these nuanced discrepancies. However, this assessment underscores the importance of context and clear annotation guidelines in achieving consistent linguistic annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4: Generative and Discriminative Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Words as Features\n",
    "In this assignment, we will convert a text to a matrix of features for the purpose of language identification. We will use data from star-wars fandom wikipedia:\n",
    "* English [Wookipedia](https://starwars.fandom.com/wiki/Main_Page)  \n",
    "* Danish [Kraftens Arkiver](https://starwars.fandom.com/da/wiki) \n",
    "* Dutch [Yodapedia](https://starwars.fandom.com/da/wiki)\n",
    "\n",
    "We have already tokenized the data for you. The data can be read like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_langid(path):\n",
    "    text = []\n",
    "    labels = []\n",
    "    for line in open(path, encoding='utf-8'):\n",
    "        tok = line.strip().split('\\t')\n",
    "        labels.append(tok[0])\n",
    "        text.append(tok[1])\n",
    "    return text, labels\n",
    "\n",
    "wooki_train_text, wooki_train_labels = load_langid('langid-data/wookipedia_langid.train.tok.txt')\n",
    "wooki_dev_text, wooki_dev_labels = load_langid('langid-data/wookipedia_langid.dev.tok.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['He even went so far as to suggest that , since they had been standing there for some time and the plague had not affected them , this plague was really a warning from the dark side .',\n",
       "  'De Ewok Catapult was een projectielwapen dat de Ewoks gebruikten .',\n",
       "  'Revenge of the Sith',\n",
       "  \"Under Slaget om Hoth bestod eskadrillen af 11 piloter , men tog nogle 'gæster ' med i deres eskadrille såsom smugleren Dash Rendar , for at få skytter nok til at bemande deres Snowspeedere .\",\n",
       "  \"He , along with the rest of Storm Squad , fell in battle while unsuccessfully defending the `` Dorin 's Sky '' from Imperial boarders .\"],\n",
       " ['en', 'nl', 'nl', 'da', 'en'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 examples\n",
    "wooki_train_text[:5], wooki_train_labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Convert the train data to \"binary word features\". This means that every instance (sentence) is represented by a vector of binary values, each of which corresponds to a word. For example (features are on the columns, input on the rows):\n",
    "\n",
    "|             | hello | bye | there | here | ... |\n",
    "|-------------|-------|-----|-------|------|-----|\n",
    "| hello there | 1     | 0   | 1     | 0    |     |\n",
    "| bye bye     | 0     | 1   | 0     | 0    |     |\n",
    "\n",
    "\n",
    "Note that this means that you will end up with a matrix of size `(#data_instances, len(vocab))` where `vocab` contains your vocabulary (i.e. all the words in the train data), and the `#data_instances` is the number of input sentences (feel free to use numpy, torch or native python lists). This matrix will be filled with 0's and 1's, indicating which features are present in which instances.\n",
    "\n",
    "**Hint**: Start with two sentences, as it is much easier to debug (and with 1 sentence, you will have only 1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 43])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def build_vocab(texts):\n",
    "    \"\"\"Build vocabulary from a list of texts.\"\"\"\n",
    "    vocab = set()\n",
    "    for text in texts:\n",
    "        words = text.split()  # Split text into words\n",
    "        vocab.update(words)\n",
    "    return {word: i for i, word in enumerate(sorted(list(vocab)))}  # Map word to its index in sorted list\n",
    "\n",
    "def text_to_binary_features(texts, vocab):\n",
    "    \"\"\"Convert texts to binary feature representation in PyTorch.\"\"\"\n",
    "    features = torch.zeros((len(texts), len(vocab)), dtype=torch.float32)  # Initialize feature matrix with zeros\n",
    "    for i, text in enumerate(texts):\n",
    "        words = set(text.split())  # Convert text to a set of unique words\n",
    "        for word in words:\n",
    "            if word in vocab:\n",
    "                features[i, vocab[word]] = 1.0  # Set feature to 1 if word is present\n",
    "    return features\n",
    "\n",
    "# Example usage\n",
    "texts = [\n",
    "    \"He even went so far as to suggest that , since they had been standing there for some time and the plague had not affected them , this plague was really a warning from the dark side .\",\n",
    "    \"De Ewok Catapult was een projectielwapen dat de Ewoks gebruikten .\"\n",
    "]\n",
    "\n",
    "# Build vocabulary from the train texts\n",
    "vocab = build_vocab(texts)\n",
    "\n",
    "# Convert texts to binary features using PyTorch\n",
    "binary_features = text_to_binary_features(texts, vocab)\n",
    "\n",
    "# Print the shape of the binary features tensor to confirm its size\n",
    "print(binary_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15000, 37816])\n"
     ]
    }
   ],
   "source": [
    "train_vocab = build_vocab(wooki_train_text)\n",
    "train_binary_features = text_to_binary_features(wooki_train_text, train_vocab)\n",
    "print(train_binary_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Convert the dev data to the same features generated from the training data. Note that no new features can be introduced at this point, check whether the size of the matrix is `(#dev_instances, len(vocab))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3000, 37816])\n"
     ]
    }
   ],
   "source": [
    "# Use the training vocabulary to convert dev texts to binary features\n",
    "dev_binary_features = text_to_binary_features(wooki_dev_text, train_vocab)\n",
    "\n",
    "# Print the shape of the binary features tensor for the dev data to confirm its size\n",
    "print(dev_binary_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Write down what are the pros and cons of representing text as `BOW` (bag-of-words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Pros and Cons of BOW Representation\n",
    "\n",
    "The Bag-of-Words (BOW) model is a text representation technique. In BOW, a text (such as a sentence) is represented as an unordered collection of words, disregarding grammar and even word order but keeping multiplicity.\n",
    "\n",
    "### Pros\n",
    "\n",
    "1. **Simplicity:** BOW is straightforward to understand and implement.\n",
    "2. **Scalability:** BOW models can easily handle large datasets and vocabularies, making them suitable for tasks like document classification and spam detection.\n",
    "3. **Effectiveness:** Despite its simplicity, BOW can be effective at capturing the frequency of words in documents, which can be very informative for tasks like topic modeling and sentiment analysis.\n",
    "\n",
    "### Cons\n",
    "1. **Loss of Context:** BOW models ignore the order of words, resulting in a loss of context, which can lead to misunderstanding the meaning of sentences (e.g., \"dog bites man\" vs. \"man bites dog\").\n",
    "2. **Ignoring Semantics:** BOW does not capture the semantics of words; synonyms are treated as different words unless specifically merged, and it doesn't account for polysemy (words with multiple meanings).\n",
    "3. **Sparsity:** The resulting feature vectors are often sparse (mostly zeros), which can be inefficient for computation and require more memory for larger vocabularies.\n",
    "4. **High Dimensionality:** The dimensionality of the feature vectors can become very high with a large vocabulary, leading to the \"curse of dimensionality,\" which can degrade the performance of machine learning models.\n",
    "5. **Word Order and Grammar:** Important aspects of language such as syntax and grammar are ignored, which can be crucial for understanding the meaning of texts.\n",
    "6. **Document Length Bias:** BOW features can be biased by document length since longer documents might have higher word counts overall, affecting the performance of some models if not normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Character n-grams\n",
    "Character n-grams can have some advantages over word-level features, as there can be more overlap and less unknown features. It is common to use a range of n-gram sizes, for example 3-6 is a common choice. Convert the following text to character n-grams, use a range of 1-3 (so unigrams, bigrams and trigrams). You do not have to make use of special start characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = 'This is a fish'\n",
    "\n",
    "ngrams = []\n",
    "\n",
    "expected_output = ['T', 'h', 'i', 's', ' ', 'i', 's', ' ', 'a', ' ', 'f', 'i', 's', 'h', 'Th', 'hi', 'is', 's ', ' i', 'is', 's ', ' a', 'a ', ' f', 'fi', 'is', 'sh', 'Thi', 'his', 'is ', 's i', ' is', 'is ', 's a', ' a ', 'a f', ' fi', 'fis', 'ish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Unigrams\n",
    "for char in input_data:\n",
    "  ngrams.append(char)\n",
    "# Bigrams\n",
    "for i in range(len(input_data)-1):\n",
    "  ngrams.append(input_data[i:i+2])\n",
    "# Trigrams\n",
    "for i in range(len(input_data)-2):\n",
    "  ngrams.append(input_data[i:i+3])\n",
    "\n",
    "print(ngrams == expected_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Naive Bayes Classifier\n",
    "\n",
    "Solve the following exercises from [Chapter 4 of Speech and Language processing](https://web.stanford.edu/~jurafsky/slp3/4.pdf):\n",
    "\n",
    "a) Exercise 4.1 from J&M: (copied here for your convenience):\n",
    "\n",
    "Assume the following likelihoods for each word being part of a positive or negative movie review, and equal prior probabilities for each class.\n",
    "\n",
    "| feature         | pos | neg     |\n",
    "| :---        |    :----:   |          ---: |\n",
    "| I      |  0.09      |  0.16  |\n",
    "| always   | 0.07        | 0.06      |\n",
    "| like      | 0.29       | 0.06   |\n",
    "| foreign      | 0.04       | 0.15   |\n",
    "| films      |  0.08      | 0.11   |\n",
    "\n",
    "- What class will Naive Bayes assign to the sentence `“I always like foreign films.”`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Solution\n",
    "\n",
    "To determine the class Naive Bayes would assign to the sentence \"I always like foreign films,\" we need to calculate the `posterior probabilities` for both classes (positive and negative) for the given sentence. The Naive Bayes classifier assumes that the features (in this case, words) are `independent` given the class. Given this assumption, we can calculate the probability of the sentence being in a class by multiplying the probabilities of the individual words given the class and then multiplying by the `prior probability` of the class. Since the question states equal prior probabilities for each class, we can ignore the priors because they would cancel out in comparison.\n",
    "\n",
    "The formula for the posterior probability of a class given a sentence is as follows, assuming class $C$ (positive or negative) and words $w_1, w_2, ..., w_n$ in the sentence:\n",
    "\n",
    "$P(C | w_1, w_2, ..., w_n) \\propto P(w_1 | C) \\times P(w_2 | C) \\times ... \\times P(w_n | C) \\times P(C)$\n",
    "\n",
    "Given the equal priors, we simplify to:\n",
    "\n",
    "$P(C | w_1, w_2, ..., w_n) \\propto P(w_1 | C) \\times P(w_2 | C) \\times ... \\times P(w_n | C)$\n",
    "\n",
    "Calculate the probabilities for both classes for the sentence \"I always like foreign films\":\n",
    "\n",
    "- For positive class (\\(pos\\)):\n",
    "  - $P(\\text{\"I\"} | pos) = 0.09$\n",
    "  - $P(\\text{\"always\"} | pos) = 0.07$\n",
    "  - $P(\\text{\"like\"} | pos) = 0.29$\n",
    "  - $P(\\text{\"foreign\"} | pos) = 0.04$\n",
    "  - $P(\\text{\"films\"} | pos) = 0.08$\n",
    "\n",
    "- For negative class (\\(neg\\)):\n",
    "  - $P(\\text{\"I\"} | neg) = 0.16$\n",
    "  - $P(\\text{\"always\"} | neg) = 0.06$\n",
    "  - $P(\\text{\"like\"} | neg) = 0.06$\n",
    "  - $P(\\text{\"foreign\"} | neg) = 0.15$\n",
    "  - $P(\\text{\"films\"} | neg) = 0.11$\n",
    "\n",
    "Compute the product of these probabilities for each class to determine which class has the higher posterior probability for the sentence.\n",
    "\n",
    "The calculated product of probabilities for the sentence \"I always like foreign films\" is (see code below):\n",
    "\n",
    "- For the positive class: $5.8464 \\times 10^{-6}$\n",
    "- For the negative class: $9.504 \\times 10^{-6}$\n",
    "\n",
    "Since the product of probabilities for the negative class is higher than that for the positive class, Naive Bayes would assign the sentence \"I always like foreign films\" to the **negative** class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.8464e-06, 9.503999999999999e-06)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probabilities for each word given the class\n",
    "probabilities_pos = [0.09, 0.07, 0.29, 0.04, 0.08]\n",
    "probabilities_neg = [0.16, 0.06, 0.06, 0.15, 0.11]\n",
    "\n",
    "# Calculate the product of probabilities for each class\n",
    "prob_product_pos = 1\n",
    "prob_product_neg = 1\n",
    "\n",
    "for p_pos, p_neg in zip(probabilities_pos, probabilities_neg):\n",
    "    prob_product_pos *= p_pos\n",
    "    prob_product_neg *= p_neg\n",
    "\n",
    "prob_product_pos, prob_product_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Exercise 4.2 from J&M (copied here for your convenience):\n",
    "\n",
    "Given the following short movie reviews, each labeled with a genre, either comedy or action:\n",
    "\n",
    "1. fun, couple, love, love **comedy**\n",
    "\n",
    "2. fast, furious, shoot **action**\n",
    "\n",
    "3. couple, fly, fast, fun, fun **comedy**\n",
    "\n",
    "4. furious, shoot, shoot, fun **action**\n",
    "\n",
    "5. fly, fast, shoot, love **action**\n",
    "\n",
    "and a new document D:\n",
    "\n",
    "```\n",
    "fast, couple, shoot, fly\n",
    "```\n",
    "\n",
    "- Compute the most likely class for D. Assume a Naive Bayes classifier and use *add-1 smoothing* for the likelihoods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Solution\n",
    "\n",
    "To compute the most likely class for the new document $D$ (\"fast, couple, shoot, fly\") using a Naive Bayes classifier with add-1 smoothing, we first need to calculate the `prior probabilities` of each class (comedy and action), the vocabulary size, and then compute the likelihoods of each word given the class with add-1 smoothing.\n",
    "\n",
    "**Step 1: Calculate Prior Probabilities**\n",
    "- Prior probability of comedy: $P(\\text{comedy})$\n",
    "- Prior probability of action: $P(\\text{action})$\n",
    "\n",
    "**Step 2: Calculate Vocabulary Size**\n",
    "The vocabulary size is the total number of unique words across all reviews.\n",
    "\n",
    "**Step 3: Compute Likelihoods with Add-1 Smoothing**\n",
    "The likelihood of a word given a class is calculated as:\n",
    "\n",
    "$P(word|class) = \\frac{count(word, class) + 1}{\\sum_{word'}(count(word', class) + 1)}$\n",
    "\n",
    "where $\\sum_{word'}$ is the sum over all words in the vocabulary.\n",
    "\n",
    "**Step 4: Compute Posterior for Each Class for Document $D$**\n",
    "The `posterior probability` for $D$ given a class is proportional to the product of the likelihoods of its words given the class, multiplied by the class's prior probability.\n",
    "\n",
    "Based on the calculations:\n",
    "\n",
    "- The prior probability of comedy is $\\frac{2}{5}=0.4$ and of action is $\\frac{3}{5}=0.6$.\n",
    "- The vocabulary size, representing the total number of unique words across all reviews, is $7$.\n",
    "\n",
    "For the new document $D$ (\"fast, couple, shoot, fly\"), the posterior probabilities, after applying add-1 smoothing (see code below):\n",
    "\n",
    "- For comedy: $7.324 \\times 10^{-5}$\n",
    "- For action: $1.715 \\times 10^{-4}$\n",
    "\n",
    "Given these posterior probabilities, the Naive Bayes classifier would classify the new document $D$ as belonging to the **action** genre, as it has the higher posterior probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'comedy': 0.4, 'action': 0.6},\n",
       " 7,\n",
       " defaultdict(float,\n",
       "             {'comedy': 7.324218750000001e-05,\n",
       "              'action': 0.00017146776406035664}))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Reviews by genre\n",
    "reviews = {\n",
    "    \"comedy\": [\n",
    "        [\"fun\", \"couple\", \"love\", \"love\"],\n",
    "        [\"couple\", \"fly\", \"fast\", \"fun\", \"fun\"]\n",
    "    ],\n",
    "    \"action\": [\n",
    "        [\"fast\", \"furious\", \"shoot\"],\n",
    "        [\"furious\", \"shoot\", \"shoot\", \"fun\"],\n",
    "        [\"fly\", \"fast\", \"shoot\", \"love\"]\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Document D words\n",
    "document_d = [\"fast\", \"couple\", \"shoot\", \"fly\"]\n",
    "\n",
    "# Step 1: Calculate the total number of documents and prior probabilities\n",
    "total_docs = sum(len(docs) for docs in reviews.values())\n",
    "prior_probs = {genre: len(docs) / total_docs for genre, docs in reviews.items()}\n",
    "\n",
    "# Step 2: Calculate vocabulary size\n",
    "vocab = set(word for docs in reviews.values() for doc in docs for word in doc)\n",
    "\n",
    "# Count words in each class\n",
    "word_counts = {genre: defaultdict(int) for genre in reviews}\n",
    "total_words_in_class = defaultdict(int)\n",
    "for genre, docs in reviews.items():\n",
    "    for doc in docs:\n",
    "        for word in doc:\n",
    "            word_counts[genre][word] += 1\n",
    "            total_words_in_class[genre] += 1\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Step 3: Compute likelihoods with add-1 smoothing\n",
    "likelihoods = {\n",
    "    genre: {word: (word_counts[genre][word] + 1) / (total_words_in_class[genre] + vocab_size) for word in vocab}\n",
    "    for genre in reviews\n",
    "}\n",
    "\n",
    "# Step 4: Compute posterior for each class for document D\n",
    "posterior_probs = defaultdict(float)\n",
    "for genre in reviews:\n",
    "    posterior_probs[genre] = prior_probs[genre]\n",
    "    for word in document_d:\n",
    "        posterior_probs[genre] *= likelihoods[genre][word]\n",
    "\n",
    "prior_probs, vocab_size, posterior_probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Naive Bayes with BOW in sklearn \n",
    "\n",
    "In this assignment, we will focus on the task of language identification. You can use the data from assignment 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_langid(path):\n",
    "    text = []\n",
    "    labels = []\n",
    "    for line in open(path, encoding='utf-8'):\n",
    "        tok = line.strip().split('\\t')\n",
    "        labels.append(tok[0])\n",
    "        text.append(tok[1])\n",
    "    return text, labels\n",
    "\n",
    "wooki_train_text, wooki_train_labels = load_langid('langid-data/wookipedia_langid.train.tok.txt')\n",
    "wooki_dev_text, wooki_dev_labels = load_langid('langid-data/wookipedia_langid.dev.tok.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['He even went so far as to suggest that , since they had been standing there for some time and the plague had not affected them , this plague was really a warning from the dark side .',\n",
       "  'De Ewok Catapult was een projectielwapen dat de Ewoks gebruikten .',\n",
       "  'Revenge of the Sith',\n",
       "  \"Under Slaget om Hoth bestod eskadrillen af 11 piloter , men tog nogle 'gæster ' med i deres eskadrille såsom smugleren Dash Rendar , for at få skytter nok til at bemande deres Snowspeedere .\",\n",
       "  \"He , along with the rest of Storm Squad , fell in battle while unsuccessfully defending the `` Dorin 's Sky '' from Imperial boarders .\"],\n",
       " ['en', 'nl', 'nl', 'da', 'en'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 examples\n",
    "wooki_train_text[:5], wooki_train_labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Train a Naive Bayes classifier with character 3-6 grams, you can make use of the scikit-learn implementations for the n-grams ([CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), you can use the range and analyser parameters) as well as Naive Bayes ([MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB)), note that there are multiple variations of Naive Bayes implementations in sklearn, the one discussed in the book/slides is the multinomial variant. \n",
    "\n",
    "**Note**: the input is a list of lists of features `x` and a list of corresponding gold labels `y`. Therefore, the following should hold `len(x) == len(y)` and their indices should match.\n",
    "Additionally, every instance in `x` should have the same length (the number of features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;countvectorizer&#x27;,\n",
       "                 CountVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(3, 6))),\n",
       "                (&#x27;multinomialnb&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;countvectorizer&#x27;,\n",
       "                 CountVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(3, 6))),\n",
       "                (&#x27;multinomialnb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(3, 6))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('countvectorizer',\n",
       "                 CountVectorizer(analyzer='char', ngram_range=(3, 6))),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create a pipeline that first transforms the data using CountVectorizer and then applies MultinomialNB classifier\n",
    "NB_model = make_pipeline(CountVectorizer(analyzer='char', ngram_range=(3, 6)), MultinomialNB())\n",
    "\n",
    "# Train the model with the training data\n",
    "NB_model.fit(wooki_train_text, wooki_train_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Run the classifier on the dev data. It is crucial that you ensure that the feature values have exactly the same order as during training. How well does it perform? (what is the accuracy?)\n",
    "\n",
    "**Note**: you cannot introduce new features here (!): you have to use the exact same features as the ones used during training.\n",
    "\n",
    "**Hint**: If the accuracy is lower than 50%, you are probably mixing up the feature order, either during training or during development or both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the development data: 0.943820\n"
     ]
    }
   ],
   "source": [
    "# b) The model is trained and can be used for predictions or evaluation\n",
    "\n",
    "predictions = NB_model.predict(wooki_dev_text)\n",
    "\n",
    "NB_accuracy = NB_model.score(wooki_dev_text, wooki_dev_labels)\n",
    "print(f\"Accuracy on the development data: {accuracy:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 7. Discriminative Classifier with BOW\n",
    "\n",
    "a) Train a `logistic regression` classifier in a similar fashion. For more information, see: [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Does it outperform the naive bayes classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulba_dev_text, bulba_dev_labels = load_langid('langid-data/bulbapedia_langid.dev.tok.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the development data: 0.943820\n"
     ]
    }
   ],
   "source": [
    "# a) Logistic regression\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create a pipeline that first transforms the data using CountVectorizer and then applies LogisticRegression classifier\n",
    "LR_model = make_pipeline(CountVectorizer(analyzer='char', ngram_range=(3, 6)), LogisticRegression(max_iter=1000))\n",
    "\n",
    "# Train the model with the training data\n",
    "LR_model.fit(wooki_train_text, wooki_train_labels)\n",
    "\n",
    "predictions = LR_model.predict(wooki_dev_text)\n",
    "\n",
    "LR_accuracy = LR_model.score(wooki_dev_text, wooki_dev_labels)\n",
    "print(f\"Accuracy on the development data: {accuracy:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears the LR and NB models perform similarly on Dev set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Now evaluate both classifiers (`logistic regression` and `naive bayes`) on the out-of-domain Bulbapedia data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy on Bulbapedia data: 0.8945\n",
      "Logistic Regression accuracy on Bulbapedia data: 0.8891\n",
      "Naive Bayes model performs better than Logistic Regression model on Bulbapedia data.\n"
     ]
    }
   ],
   "source": [
    "# b)\n",
    "# Evaluate Naive Bayes model on Bulbapedia data\n",
    "NB_predictions_bulba = NB_model.predict(bulba_dev_text)\n",
    "NB_accuracy_bulba = NB_model.score(bulba_dev_text, bulba_dev_labels)\n",
    "print(f\"Naive Bayes accuracy on Bulbapedia data: {NB_accuracy_bulba:.4f}\")\n",
    "\n",
    "# Evaluate Logistic Regression model on Bulbapedia data\n",
    "LR_predictions_bulba = LR_model.predict(bulba_dev_text)\n",
    "LR_accuracy_bulba = LR_model.score(bulba_dev_text, bulba_dev_labels)\n",
    "print(f\"Logistic Regression accuracy on Bulbapedia data: {LR_accuracy_bulba:.4f}\")\n",
    "\n",
    "# Compare performance\n",
    "if LR_accuracy_bulba > NB_accuracy_bulba:\n",
    "    print(\"Logistic Regression model performs better than Naive Bayes model on Bulbapedia data.\")\n",
    "else:\n",
    "    print(\"Naive Bayes model performs better than Logistic Regression model on Bulbapedia data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analysis\n",
    "There are two obvious ways to inspect the classifiers in more detail: by inspecting a confusion matrix and by\n",
    "examining the feature weights. Pick at least one of the following options:\n",
    "\n",
    "### Confusion matrix\n",
    "a) Plot a confusion matrix for the logistic regression BOW model trained in `7a)` when used on Bulbapedia data, and inspect the errors (it is not important how you visualize the results: a table, a figure, or even an ASCII table will suffice). \n",
    "Are there any interesting trends?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jackh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Generate predictions on the Bulbapedia development set\n",
    "bulba_predictions = LR_model.predict(bulba_dev_text)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(bulba_dev_labels, bulba_predictions, labels=LR_model.classes_)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_confusion_matrix(LR_model, bulba_dev_text, bulba_dev_labels,\n",
    "                      display_labels=LR_model.classes_,\n",
    "                      cmap=plt.cm.Blues,\n",
    "                      normalize=None,\n",
    "                      ax=ax)\n",
    "plt.title('Confusion Matrix for Logistic Regression Model on Bulbapedia Data')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix provided for the Logistic Regression model on Bulbapedia data shows the following trends:\n",
    "\n",
    "1. **High True Positives for English (en) and Dutch (nl):** The model correctly identifies a large number of English and Dutch samples, as indicated by the high numbers in the diagonal for 'en' and 'nl' classes.\n",
    "\n",
    "2. **Misclassification of Danish (da) as English (en):** A significant number of Danish samples are misclassified as English. This could be due to the similarity between some Danish and English words, or it may suggest that the model has learned patterns that are common in English but also appear in Danish.\n",
    "\n",
    "3. **Some English (en) Misclassified as Dutch (nl) and vice versa:** There are instances where English texts are misclassified as Dutch and Dutch texts as English. This might be because these languages share a lot of vocabulary and grammatical features, leading to confusion.\n",
    "\n",
    "4. **Least Misclassification for Dutch (nl):** Dutch has the least number of texts misclassified as other languages, which might imply that the Dutch language features are more distinct compared to English and Danish in this dataset, or the model has learned to recognize Dutch more accurately.\n",
    "\n",
    "5. **Misclassification of Danish (da) as Dutch (nl) and vice versa:** There are a few instances of Danish being classified as Dutch and Dutch as Danish. This suggests that there are some similarities between the two languages that the model is picking up on, which could be due to shared Germanic roots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          da       0.60      0.90      0.72       118\n",
      "          en       0.94      0.91      0.93       500\n",
      "          nl       0.94      0.86      0.90       500\n",
      "\n",
      "    accuracy                           0.89      1118\n",
      "   macro avg       0.83      0.89      0.85      1118\n",
      "weighted avg       0.91      0.89      0.89      1118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate the classification report, which includes precision, recall, and F1 score for each class\n",
    "report = classification_report(bulba_dev_labels, bulba_predictions, target_names=LR_model.classes_)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report provides several important metrics for each language:\n",
    "\n",
    "- **Precision**: Indicates how many of the items identified by the model as belonging to a certain class actually belong to that class.\n",
    "- **Recall**: Indicates how many items of a certain class were correctly identified by the model out of all actual members of that class in the dataset.\n",
    "- **F1-Score**: Combines precision and recall into a single metric by taking their harmonic mean. It's especially useful when the class distribution is unbalanced.\n",
    "- **Support**: The number of actual occurrences of the class in the dataset.\n",
    "\n",
    "Here's the interpretation of the results:\n",
    "\n",
    "- **Danish (da)**: \n",
    "  - Precision is relatively low at 0.60, indicating that when the model predicts an item is in Danish, it is correct 60% of the time.\n",
    "  - Recall is high at 0.90, meaning the model successfully identifies 90% of all Danish items in the dataset.\n",
    "  - The F1-score, which balances precision and recall, is 0.72, suggesting that while the model is quite good at detecting Danish, when it does, it is less reliable than for English and Dutch.\n",
    "  - The support of 118 indicates a smaller number of Danish samples compared to English and Dutch.\n",
    "\n",
    "- **English (en)**:\n",
    "  - Precision is high at 0.94, suggesting a high level of reliability in the model's English predictions.\n",
    "  - Recall is also high at 0.91, meaning the model identifies 91% of all English items correctly.\n",
    "  - The F1-score is 0.93, which is the highest of the three languages, indicating the best overall balance of precision and recall for English.\n",
    "  - English has the highest support with 500, meaning it has more samples in the dataset, which typically helps in training more reliable classifiers.\n",
    "\n",
    "- **Dutch (nl)**:\n",
    "  - Precision is high at 0.94, on par with English.\n",
    "  - Recall is somewhat lower at 0.86, indicating that while the model's predictions are reliable, it misses more Dutch items than it does English items.\n",
    "  - The F1-score is 0.90, which is slightly lower than English but still indicates a strong performance.\n",
    "  - Dutch also has a high support value of 500, which means a large number of samples for this class as well.\n",
    "\n",
    "- **Overall Accuracy**: \n",
    "  - The model has an overall accuracy of 0.89, which means that it correctly identifies the language 89% of the time across all predictions.\n",
    "\n",
    "- **Macro Average**: \n",
    "  - The macro average treats all classes equally, averaging the metric scores without taking the support into account. The macro avg F1-score is 0.85, which is a strong performance but slightly lower than the weighted average.\n",
    "\n",
    "- **Weighted Average**: \n",
    "  - The weighted average takes the support into account, giving more weight to classes with more samples. The weighted avg F1-score is 0.89, which is closer to the overall accuracy and reflects the influence of the more numerous English and Dutch samples.\n",
    "\n",
    "In summary, English has the best F1-score and thus the best performance according to this metric, followed closely by Dutch. Danish has the lowest F1-score, which is significantly affected by its lower precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature weights\n",
    "In scikit-learn, you can inspect the internal weights given to each feature in the `.coef_` variable. \n",
    "\n",
    "b) Inspect the most important features for both the naive bayes and logistic regression classifiers. Are there any interesting differences?\n",
    "\n",
    "**Hint**: The weights are given per class, so you can either inspect three lists, or compute the average importance\n",
    "(make sure to use the absolute feature values for the average).\n",
    "\n",
    "Top features for both models according to the average importance of their weights across all classes. [::-1] reverses the indices to sort from highest to lowest. Get top 10 features to retrieve with [:10].\n",
    "\n",
    "For Naive Bayes, the `.feature_log_prob_` gives the log probability of each feature given a class, while for Logistic Regression, `.coef_ gives` the actual weights that multiply the feature values to get the decision function. High absolute values of weights in Logistic Regression imply greater importance in the classification decision, while for Naive Bayes, higher log probabilities indicate a stronger relationship with the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top features for Logistic Regression:\n",
      "['[ 2' '200' 'maj' 'tap' '[ 1' 'ed ' 'de ' 'maj ' 'aan' 'gar']\n",
      "\n",
      "Top features for Naive Bayes:\n",
      "[' s-0d3' 't om u' 't opwa' 'ku te' 'ku te ' 'ku van' 'ku ve' 'ku ver'\n",
      " 'ku vo' 'ku voz']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# For Logistic Regression\n",
    "# Get feature names from the vectorizer\n",
    "feature_names = LR_model.named_steps['countvectorizer'].get_feature_names_out()\n",
    "\n",
    "# Get the coefficients from the Logistic Regression model\n",
    "lr_coefs = LR_model.named_steps['logisticregression'].coef_\n",
    "\n",
    "# Get the absolute values of the coefficients for each class and then average them\n",
    "lr_avg_coefs = np.mean(np.abs(lr_coefs), axis=0)\n",
    "\n",
    "# Get the indices of the sorted averaged coefficients\n",
    "lr_sorted_indices = np.argsort(lr_avg_coefs)[::-1]\n",
    "\n",
    "# Get the top features for Logistic Regression\n",
    "top_lr_features = feature_names[lr_sorted_indices[:10]]  # change 10 to desired number of top features\n",
    "\n",
    "# For Naive Bayes\n",
    "# Get the log probabilities of features for each class\n",
    "nb_log_prob = NB_model.named_steps['multinomialnb'].feature_log_prob_\n",
    "\n",
    "# Get the absolute values of the log probabilities and then average them\n",
    "nb_avg_log_prob = np.mean(np.abs(nb_log_prob), axis=0)\n",
    "\n",
    "# Get the indices of the sorted averaged log probabilities\n",
    "nb_sorted_indices = np.argsort(nb_avg_log_prob)[::-1]\n",
    "\n",
    "# Get the top features for Naive Bayes\n",
    "top_nb_features = feature_names[nb_sorted_indices[:10]]  # change 10 to desired number of top features\n",
    "\n",
    "# Compare the top features\n",
    "print(\"Top features for Logistic Regression:\")\n",
    "print(top_lr_features)\n",
    "print(\"\\nTop features for Naive Bayes:\")\n",
    "print(top_nb_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N-gram character features from text.\n",
    "\n",
    "**Logistic Regression Features:**\n",
    "- The n-grams like `'de '` (likely the beginning of Dutch definite articles or prepositions), `'ed '` (possibly the end of a past-tense verb in English), and `'aan'` (Dutch for \"on\" or part of a verb) suggest that the Logistic Regression model is picking up on common substrings that may be indicative of the language's grammar and common words.\n",
    "- The n-grams `'maj'` and `'gar'` could be parts of words that are distinctive to certain languages within the dataset. For instance, `'maj'` could be part of a word like \"majestic\" in English or \"majestæt\" in Danish, and `'gar'` might be from \"garçon\" in English borrowed from French or \"garage\" in Dutch.\n",
    "- N-grams such as `'[ 2'` and `'[ 1'` might be artifacts from the dataset.\n",
    "\n",
    "**Naive Bayes Features:**\n",
    "- The Naive Bayes features like `'ku te'`, `'ku van'`, `'ku ver'`, and `'ku vo'` seem to be part of larger words or sequences that may be very common in one of the languages. It's not immediately clear what language these could belong to without additional context.\n",
    "- Sequences such as `'t om u'` and `'t opwa'` might be more indicative of Dutch, as the `'t` could be the article \"het\" abbreviated and common verb prefixes like \"om\" (around) and \"opwa\" (upward).\n",
    "\n",
    "**Interpretation Differences:**\n",
    "- The features important to the Logistic Regression model seem to include both language-specific character sequences and possible formatting or numbering from the data, suggesting that it might be leveraging both linguistic and structural cues from the text.\n",
    "- The Naive Bayes features are less immediately interpretable and seem to focus on more unique sequences that might be highly indicative of the language but are less obviously connected to language structure.\n",
    "\n",
    "The differences in the features may indicate differences in the strategies the two models use to classify text: Logistic Regression might be picking up on more general patterns that apply across multiple instances, while Naive Bayes may be capturing more specific cues that are highly predictive of certain classes. This could be due to the intrinsic differences in how these models learn from the data."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
