{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Algebra Assignment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step: 1\n",
    "- Compute the size of the graph, store it in a variable\n",
    "- Compute the reverse of the graph, using method reverse() and an array \"branching\" such that \"branching[i]\"\n",
    "    is the number of nodes linked to from node i. \n",
    "- Compute a list of dangling nodes\n",
    "- Compute the initial approx of the ranking vector corresponding to x0 of PageNoteNotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Setup\n",
    "G = nx.read_edgelist('p2p-Gnutella08-mod.txt', comments='#',    # NB! Gnutella.txt must be in the directory as specified\n",
    "                     create_using=nx.DiGraph(), \n",
    "                     delimiter='\\t', \n",
    "                     nodetype=int, \n",
    "                     encoding='utf-8')\n",
    "\n",
    "graph_size = G.size()\n",
    "G_reversed = nx.DiGraph.reverse(G)       # returns the reverse of the graph, i.e. all the edges are reversed\n",
    "\n",
    "# create an array \"branching\" such that branching[i] is the number of nodes linked to from node i, that is the out-degree of node i\n",
    "branching = np.zeros(graph_size, dtype=int)\n",
    "for idx, out_degree in G.out_degree():\n",
    "    branching[idx] = out_degree\n",
    "\n",
    "# find dangling nodes in the graph, that is nodes with out-degree 0\n",
    "dangling_nodes = np.where(branching == 0)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Surfer implementation with networkx\n",
    "\n",
    "def random_walk(damping_factor, num_iterations, wantNumOfVisits = False):\n",
    "    # Select the initial random node \n",
    "    random_node = random.choice([i for i in range(G.number_of_nodes())])\n",
    "\n",
    "    # initialize the initial count for all nodes as zero\n",
    "    dict_counter = {}\n",
    "    for i in range(G.number_of_nodes()):\n",
    "        dict_counter[i] = 0\n",
    "\n",
    "    # Since we start with initial node, this node gets a count of 1 to start with\n",
    "    dict_counter[random_node] += 1\n",
    "\n",
    "    # Traversing through the neighrbors of random node\n",
    "    for i in range(num_iterations):     # num_iterations is the number of walks done in total\n",
    "        m = random.random()\n",
    "        list_of_neighbors = list(G.neighbors(random_node))\n",
    "        if random_node in dangling_nodes:     # if the node is a dangling node, then jump to a random node\n",
    "                random_node = random.choice([i for i in range(G.number_of_nodes())])\n",
    "                dict_counter[random_node] += 1\n",
    "        else:\n",
    "            if m < 1-damping_factor:  # probablity walk to random neighbor\n",
    "                random_node = random.choice(list_of_neighbors)   # select a random neighbor\n",
    "                dict_counter[random_node] += 1\n",
    "            else:       # jump to a random node, damping_factor% probability\n",
    "                random_node = random.choice([i for i in range(G.number_of_nodes())])\n",
    "                dict_counter[random_node] += 1\n",
    "    \n",
    "    # sort the dictionary by value in descending order\n",
    "    sorted_random_walk = sorted(dict_counter.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "    if wantNumOfVisits:\n",
    "        return sorted_random_walk[:10]      # return the top 10 nodes with the most visits with their number of visits\n",
    "    else:\n",
    "        return list(map(operator.itemgetter(0), sorted_random_walk[:10]))     # return without the number of visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PageRank implementation with networkx (done naively)\n",
    "\n",
    "def pageRankNaive(damping_factor, num_iterations):\n",
    "    # compute mSx_k, this is done only once\n",
    "    mSx_k = np.full(graph_size, 1/graph_size) * damping_factor   \n",
    "\n",
    "    # initialize x_k0 as x_kx\n",
    "    x_kx = np.full(graph_size, 1/graph_size) \n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        # compute Dx_k:\n",
    "        temp_sum_Dx = 0\n",
    "        for i in range(graph_size):\n",
    "            if i in dangling_nodes:\n",
    "                temp_sum_Dx += x_kx[i]/graph_size\n",
    "        Dx_k = np.full(graph_size, temp_sum_Dx)\n",
    "\n",
    "        # compute Ax_k by looping over the backlinks to i:\n",
    "        Ax_k = np.zeros(graph_size)\n",
    "        for i in G.nodes():\n",
    "            temp_sum_Ax = 0\n",
    "            for j in G_reversed.out_edges(i):\n",
    "                if branching[j[1]] != 0:\n",
    "                    temp_sum_Ax += x_kx[j[1]]/branching[j[1]]\n",
    "            Ax_k[i] = temp_sum_Ax\n",
    "\n",
    "        # putting all together\n",
    "        x_kx = (1-damping_factor)*Ax_k + (1-damping_factor)*Dx_k + mSx_k\n",
    "\n",
    "    return (-x_kx).argsort()[:10]    # return the top 10 nodes with the highest PageRank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0 13854 13853 13852 13851 13850 13849 13848 13855 13847]\n",
      "[127 266 249 123 352 367 424 264 251 427]\n",
      "[ 367  249  266  127  145  123  264  427  122 1317]\n",
      "[ 367  249  145  266  264  127  123  122 1317    5]\n",
      "[ 367  249  145  264  266  127  123  122 1317    5]\n",
      "[ 367  249  145  264  266  123  127  122 1317    5]\n",
      "as you can see from result below, it takes 4 iterations for the top 10 to stablise\n"
     ]
    }
   ],
   "source": [
    "# print a list of the 10 highest ranked nodes in the PageRank algorithm for Gnutella graph\n",
    "# Approx number of iterations of PageRank algorithm needed for the top 10 to stablise\n",
    "\n",
    "for i in range(6):\n",
    "    page_rank = pageRankNaive(0.15, i)  # 0.15 is the damping factor\n",
    "    print(page_rank)\n",
    "\n",
    "print(\"as you can see from result below, it takes 4 iterations for the top 10 to stablise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1mUntyped global name 'G':\u001b[0m \u001b[1m\u001b[1mCannot determine Numba type of <class 'networkx.classes.digraph.DiGraph'>\u001b[0m\n\u001b[1m\nFile \"..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_22124\\2092335367.py\", line 6:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# print a list of the 10 most visited nodes in the Random Surfer simulation for Gnutella graph\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mprint\u001b[39m(random_walk(\u001b[39m0.15\u001b[39m, \u001b[39m500_000\u001b[39m, \u001b[39mFalse\u001b[39;00m))      \u001b[39m# 0.15 is the damping factor, 500_000 walks, do not display number of visits for each node\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mit takes approximately 500_000 walks to get a result similar to the page rank algorithm\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jackh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numba\\core\\dispatcher.py:468\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args\u001b[1;34m(self, *args, **kws)\u001b[0m\n\u001b[0;32m    464\u001b[0m         msg \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(e)\u001b[39m.\u001b[39mrstrip()\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mThis error may have been caused \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    465\u001b[0m                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mby the following argument(s):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00margs_str\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    466\u001b[0m         e\u001b[39m.\u001b[39mpatch_message(msg)\n\u001b[1;32m--> 468\u001b[0m     error_rewrite(e, \u001b[39m'\u001b[39;49m\u001b[39mtyping\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    469\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mUnsupportedError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    470\u001b[0m     \u001b[39m# Something unsupported is present in the user code, add help info\u001b[39;00m\n\u001b[0;32m    471\u001b[0m     error_rewrite(e, \u001b[39m'\u001b[39m\u001b[39munsupported_error\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jackh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numba\\core\\dispatcher.py:409\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args.<locals>.error_rewrite\u001b[1;34m(e, issue_type)\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    408\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(\u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1mUntyped global name 'G':\u001b[0m \u001b[1m\u001b[1mCannot determine Numba type of <class 'networkx.classes.digraph.DiGraph'>\u001b[0m\n\u001b[1m\nFile \"..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_22124\\2092335367.py\", line 6:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\u001b[0m"
     ]
    }
   ],
   "source": [
    "# print a list of the 10 most visited nodes in the Random Surfer simulation for Gnutella graph\n",
    "\n",
    "print(random_walk(0.15, 500_000, False))      # 0.15 is the damping factor, 500_000 walks, do not display number of visits for each node\n",
    "\n",
    "print(\"it takes approximately 500_000 walks to get a result similar to the page rank algorithm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5f0bfb910b5f89afee0c4e65874b118d019a6f05b0e3b9906c17a1424dc1b44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
